import wave
import time
import numpy as np
import matplotlib.pyplot as plt
import tkinter as tk
from threading import Thread
import subprocess  # NEW: Used to call the ML script
import sys

# Parameters for audio
sample_rate = 44100  # Hz
sample_width = 2     # 16-bit audio
num_channels = 1     # Mono audio

recording = False  # Global variable to control recording
audio_queue = []  # Queue to notify GUI
all_data_buffer = []  # Store audio data for later plotting

def log_message(message):
    print(f"{time.strftime('%Y-%m-%d %H:%M:%S')} - {message}")

def normalize_data(data, max_value, sample_width):
    max_amplitude = (2 ** (sample_width * 8 - 1)) - 1
    data_array = np.array(data, dtype=np.float32)
    normalized_data = np.int16(data_array * max_amplitude / max_value)
    return normalized_data.tobytes()

def process_audio_data(data):
    # Basic processing: remove DC offset and normalize
    data_array = np.array(data, dtype=np.float32)
    data_array -= np.mean(data_array)  # Remove DC offset
    max_val = np.max(np.abs(data_array)) or 1  # Avoid divide-by-zero
    normalized = data_array / max_val
    return normalized

def plot_data():
    plt.figure(figsize=(10, 4))
    plt.plot(all_data_buffer)
    plt.title('Processed Waveform')
    plt.xlabel('Sample Number')
    plt.ylabel('Amplitude')
    plt.grid()
    plt.show()

def plot_frequency_spectrum():
    fft_data = np.fft.fft(all_data_buffer)
    fft_magnitude = np.abs(fft_data)
    freqs = np.fft.fftfreq(len(all_data_buffer), 1 / sample_rate)
    positive_freqs = freqs[:len(freqs)//2]
    positive_magnitude = fft_magnitude[:len(fft_magnitude)//2]
    
    plt.figure(figsize=(10, 6))
    plt.plot(positive_freqs, positive_magnitude)
    plt.title('Simulated Frequency Spectrum')
    plt.xlabel('Frequency (Hz)')
    plt.ylabel('Magnitude')
    plt.grid()
    plt.show()

def record_audio():
    global recording, all_data_buffer
    log_message("Simulated recording started...")
    
    start_time = time.time()
    
    while recording:
        sample_data = np.random.randint(0, 1023)
        all_data_buffer.append(sample_data)
        
        elapsed_time = time.time() - start_time
        if elapsed_time >= 1:
            try:
                with wave.open('output_raw.wav', 'wb') as audio_file:
                    audio_file.setnchannels(num_channels)
                    audio_file.setsampwidth(sample_width)
                    audio_file.setframerate(sample_rate)
                    normalized_data = normalize_data(all_data_buffer, 1023, sample_width)
                    audio_file.writeframes(normalized_data)
                log_message(f"Recorded {int(elapsed_time)} seconds of audio")
                start_time = time.time()
            except Exception as e:
                log_message(f"Error writing WAV file: {e}")
        
        time.sleep(1 / sample_rate)

    # Save final raw WAV file
    try:
        with wave.open('output_raw.wav', 'wb') as audio_file:
            audio_file.setnchannels(num_channels)
            audio_file.setsampwidth(sample_width)
            audio_file.setframerate(sample_rate)
            normalized_data = normalize_data(all_data_buffer, 1023, sample_width)
            audio_file.writeframes(normalized_data)
        log_message("Raw recording saved as output_raw.wav.")
    except Exception as e:
        log_message(f"Error writing raw WAV file: {e}")

    # Process and save processed WAV file
    try:
        processed = process_audio_data(all_data_buffer)
        processed_int16 = np.int16(processed * ((2 ** (sample_width * 8 - 1)) - 1))
        with wave.open('output_processed.wav', 'wb') as audio_file:
            audio_file.setnchannels(num_channels)
            audio_file.setsampwidth(sample_width)
            audio_file.setframerate(sample_rate)
            audio_file.writeframes(processed_int16.tobytes())
        log_message("Processed recording saved as output_processed.wav.")
    except Exception as e:
        log_message(f"Error writing processed WAV file: {e}")
    
    root.after(0, plot_data)
    root.after(0, plot_frequency_spectrum)
    
    audio_queue.append("Recording complete")
    recording = False

def start_recording():
    global recording
    if not recording:
        recording = True
        Thread(target=record_audio, daemon=True).start()

def stop_recording():
    global recording
    recording = False
    log_message("Recording stopped.")

# NEW: Define the analyze_audio function to call the ML script with inputs
def analyze_audio():
    """
    Call the ML script (rfcmodel.py) with the processed .wav file,
    age, and gender as command line arguments.
    Expected command line format:
      python rfcmodel.py "path to .wav file" "age" gender
      e.g., python rfcmodel.py "output_processed.wav" 51 male
    """
    # Retrieve age from entry widget
    age_str = age_entry.get().strip()
    if not age_str.isdigit():
        log_message("Please enter a valid age (numeric).")
        return
    # Retrieve and validate gender selection (ML requires 'male' or 'female')
    gender = gender_var.get().lower()
    if gender not in ["male", "female"]:
        log_message("Please select a valid gender (Male or Female) for analysis.")
        return

    # Processed .wav file path
    wav_file = "output_Sp.wav"
    
    # NEW: Construct command with sys.executable so that the same interpreter is used
    command = [sys.executable, "rfcmodel.py", wav_file, age_str, gender]
    log_message(f"Running ML analysis: {' '.join(command)}")
    try:
        result = subprocess.run(command, capture_output=True, text=True)
        log_message("ML Analysis Output:")
        log_message(result.stdout)
        if result.stderr:
            log_message("ML Analysis Errors:")
            log_message(result.stderr)
    except Exception as e:
        log_message(f"ML Analysis error: {e}")

# Create GUI
root = tk.Tk()
root.title("Dysphagia Detection Device")

tk.Label(root, text="Dysphagia Detection Device", font=("Arial", 14)).pack(pady=10)

tk.Button(root, text="Start Recording", command=start_recording, bg="green", fg="black", font=("Arial", 12)).pack(pady=5)
tk.Button(root, text="Stop Recording", command=stop_recording, bg="red", fg="black", font=("Arial", 12)).pack(pady=5)
tk.Button(root, text="Quit", command=root.quit, font=("Arial", 12)).pack(pady=10)

# --- Add radiobuttons for user's biological sex ---
gender_frame = tk.Frame(root)
gender_frame.pack(pady=10)

tk.Label(gender_frame, text="Select Biological Sex:", font=("Arial", 12)).pack(side=tk.LEFT, padx=(0, 10))
# Create a Tkinter StringVar to hold the selected value; default set to 'N/A'
gender_var = tk.StringVar(value="N/A")
# Create radiobuttons that update gender_var accordingly
tk.Radiobutton(gender_frame, text="Male", variable=gender_var, value="Male", font=("Arial", 12)).pack(side=tk.LEFT)
tk.Radiobutton(gender_frame, text="Female", variable=gender_var, value="Female", font=("Arial", 12)).pack(side=tk.LEFT)
tk.Radiobutton(gender_frame, text="N/A", variable=gender_var, value="N/A", font=("Arial", 12)).pack(side=tk.LEFT)

# NEW: Add entry for Age and a button to trigger ML analysis
analysis_frame = tk.Frame(root)  # NEW:
analysis_frame.pack(pady=10)  # NEW:

tk.Label(analysis_frame, text="Enter Age:", font=("Arial", 12)).pack(side=tk.LEFT, padx=(0, 10))  # NEW:
age_entry = tk.Entry(analysis_frame, font=("Arial", 12), width=5)  # NEW:
age_entry.pack(side=tk.LEFT)  # NEW:

tk.Button(analysis_frame, text="Analyze", command=analyze_audio, font=("Arial", 12)).pack(side=tk.LEFT, padx=10)  # NEW:

root.mainloop()
