import wave
import time
import numpy as np
import matplotlib.pyplot as plt
import tkinter as tk
from threading import Thread

# Parameters for audio
sample_rate = 44100  # Hz
sample_width = 2     # 16-bit audio
num_channels = 1     # Mono audio

recording = False  # Global variable to control recording
audio_queue = []  # Queue to notify GUI
all_data_buffer = []  # Store audio data for later plotting

def log_message(message):
    print(f"{time.strftime('%Y-%m-%d %H:%M:%S')} - {message}")

def normalize_data(data, max_value, sample_width):
    max_amplitude = (2 ** (sample_width * 8 - 1)) - 1
    data_array = np.array(data, dtype=np.float32)
    normalized_data = np.int16(data_array * max_amplitude / max_value)
    return normalized_data.tobytes()

def process_audio_data(data):
    # Basic processing: remove DC offset and normalize
    data_array = np.array(data, dtype=np.float32)
    data_array -= np.mean(data_array)  # Remove DC offset
    max_val = np.max(np.abs(data_array)) or 1  # Avoid divide-by-zero
    normalized = data_array / max_val
    return normalized

def plot_data():
    plt.figure(figsize=(10, 4))
    plt.plot(all_data_buffer)
    plt.title('Processed Waveform')
    plt.xlabel('Sample Number')
    plt.ylabel('Amplitude')
    plt.grid()
    plt.show()

def plot_frequency_spectrum():
    fft_data = np.fft.fft(all_data_buffer)
    fft_magnitude = np.abs(fft_data)
    freqs = np.fft.fftfreq(len(all_data_buffer), 1 / sample_rate)
    positive_freqs = freqs[:len(freqs)//2]
    positive_magnitude = fft_magnitude[:len(fft_magnitude)//2]
    
    plt.figure(figsize=(10, 6))
    plt.plot(positive_freqs, positive_magnitude)
    plt.title('Simulated Frequency Spectrum')
    plt.xlabel('Frequency (Hz)')
    plt.ylabel('Magnitude')
    plt.grid()
    plt.show()

def record_audio():
    global recording, all_data_buffer
    log_message("Simulated recording started...")
    
    start_time = time.time()
    
    while recording:
        sample_data = np.random.randint(0, 1023)
        all_data_buffer.append(sample_data)
        
        elapsed_time = time.time() - start_time
        if elapsed_time >= 1:
            try:
                with wave.open('output_raw.wav', 'wb') as audio_file:
                    audio_file.setnchannels(num_channels)
                    audio_file.setsampwidth(sample_width)
                    audio_file.setframerate(sample_rate)
                    normalized_data = normalize_data(all_data_buffer, 1023, sample_width)
                    audio_file.writeframes(normalized_data)
                log_message(f"Recorded {int(elapsed_time)} seconds of audio")
                start_time = time.time()
            except Exception as e:
                log_message(f"Error writing WAV file: {e}")
        
        time.sleep(1 / sample_rate)

    # Save final raw WAV file
    try:
        with wave.open('output_raw.wav', 'wb') as audio_file:
            audio_file.setnchannels(num_channels)
            audio_file.setsampwidth(sample_width)
            audio_file.setframerate(sample_rate)
            normalized_data = normalize_data(all_data_buffer, 1023, sample_width)
            audio_file.writeframes(normalized_data)
        log_message("Raw recording saved as output_raw.wav.")
    except Exception as e:
        log_message(f"Error writing raw WAV file: {e}")

    # Process and save processed WAV file
    try:
        processed = process_audio_data(all_data_buffer)
        processed_int16 = np.int16(processed * ((2 ** (sample_width * 8 - 1)) - 1))
        with wave.open('output_processed.wav', 'wb') as audio_file:
            audio_file.setnchannels(num_channels)
            audio_file.setsampwidth(sample_width)
            audio_file.setframerate(sample_rate)
            audio_file.writeframes(processed_int16.tobytes())
        log_message("Processed recording saved as output_processed.wav.")
    except Exception as e:
        log_message(f"Error writing processed WAV file: {e}")
    
    # Schedule plotting in the main thread using root.after()
    root.after(0, plot_data)
    root.after(0, plot_frequency_spectrum)
    
    audio_queue.append("Recording complete")
    recording = False

def start_recording():
    global recording
    if not recording:
        recording = True
        Thread(target=record_audio, daemon=True).start()

def stop_recording():
    global recording
    recording = False
    log_message("Recording stopped.")

# Create GUI
root = tk.Tk()
root.title("Dysphagia Detection Device")

tk.Label(root, text="Dysphagia Detection Device", font=("Arial", 14)).pack(pady=10)

tk.Button(root, text="Start Recording", command=start_recording, bg="green", fg="black", font=("Arial", 12)).pack(pady=5)
tk.Button(root, text="Stop Recording", command=stop_recording, bg="red", fg="black", font=("Arial", 12)).pack(pady=5)
tk.Button(root, text="Quit", command=root.quit, font=("Arial", 12)).pack(pady=10)

# --- Added Radiobuttons for Biological Sex Selection ---
# Create a frame to hold the radiobuttons
gender_frame = tk.Frame(root)
gender_frame.pack(pady=10)

# Label for the radiobuttons
tk.Label(gender_frame, text="Select Biological Sex:", font=("Arial", 12)).pack(side=tk.LEFT, padx=(0, 10))

# Create a Tkinter StringVar to hold the selection with default set to 'N/A'
gender_var = tk.StringVar(value="N/A")

# Create the radiobuttons
tk.Radiobutton(gender_frame, text="Male", variable=gender_var, value="Male", font=("Arial", 12)).pack(side=tk.LEFT)
tk.Radiobutton(gender_frame, text="Female", variable=gender_var, value="Female", font=("Arial", 12)).pack(side=tk.LEFT)
tk.Radiobutton(gender_frame, text="N/A", variable=gender_var, value="N/A", font=("Arial", 12)).pack(side=tk.LEFT)

# The variable 'gender_var' will hold the selection for later use in your ML code

root.mainloop()
